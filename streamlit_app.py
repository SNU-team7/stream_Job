# -------------------------------
# Imports for the RAG Chatbot
# -------------------------------
from langchain.docstore.document import Document

from langchain_openai import OpenAIEmbeddings

from langchain_community.vectorstores import Weaviate
import weaviate
from openai import OpenAI

# -------------------------------
# Credentials and Endpoints
# -------------------------------
import pandas as pd
import plotly.graph_objects as go
import streamlit as st
import seaborn as sns
import matplotlib.pyplot as plt
import base64
import matplotlib.colors as mcolors  # ìƒ‰ìƒ ì²˜ë¦¬ë¥¼ ìœ„í•´ ì¶”ê°€
import plotly.express as px
from data_preprocessing import preprocess_data
import random
import altair as alt
from streamlit_folium import folium_static
import folium
from folium.plugins import MarkerCluster
import io
import numpy as np
import time
import json
import networkx as nx
from pyvis.network import Network
from streamlit.components.v1 import html

st.set_page_config(
    page_title="ê°œë°œì ì±„ìš© ê³µê³  íŠ¸ë Œë“œ", 
    layout="wide", 
    page_icon="ğŸ’»", 
    initial_sidebar_state="collapsed"
)

# ê¸°ë³¸ í—¤ë” ìˆ¨ê¸°ê¸° ìœ„í•œ ìŠ¤íƒ€ì¼ ì¶”ê°€
header_style = """
    <style>
        /* ê¸°ë³¸ Streamlit í—¤ë” ìˆ¨ê¸°ê¸° */
        .css-1v3fvcr {display: none;} /* í—¤ë” ìˆ¨ê¸°ê¸° (ë²„íŠ¼, ë¡œê³  ë“±) */
        /* ê¸°ë³¸ Streamlit í—¤ë” ìˆ¨ê¸°ê¸° */
        header {visibility: hidden;}
        /* ê¸°ë³¸ ë©”ë‰´ ìˆ¨ê¸°ê¸° */
        #MainMenu {visibility: hidden;}
        /* í‘¸í„° ìˆ¨ê¸°ê¸° */
        footer {visibility: hidden;}

        .header {
            background-color: white;
            padding: 60px 20px;  /* ìœ„ì•„ë˜ paddingì„ ì¢í˜€ì„œ ë†’ì´ ì¤„ì´ê¸° */
            position: fixed;
            top: 0;
            left: 0;
            width: 100%;
            box-shadow: 0 4px 20px rgba(0, 0, 0, 0.2); /* ìœ„ìª½ì— ê·¸ë¦¼ì ì¶”ê°€ */
            z-index: 999;
        }
        .header .logo {
            display: flex;
            justify-content: flex-start;  /* ì™¼ìª½ ì •ë ¬ */
            align-items: center;
            position: absolute;
            top: 0px;  /* ìœ„ì—ì„œ ì¡°ê¸ˆ ì•„ë˜ë¡œ */
            left: 80px;  /* ì™¼ìª½ì—ì„œ ì‚´ì§ ì˜¤ë¥¸ìª½ìœ¼ë¡œ */
        }
        .header img {
            width: 160px;  /* ì´ë¯¸ì§€ í¬ê¸° ì¡°ì • */
        }
        .header .menu {
            display: flex;
            gap: 20px;  /* ë©”ë‰´ í•­ëª© ê°„ ê°„ê²© */
            position: absolute;
            top: 42px;  /* ì´ë¯¸ì§€ ì•„ë˜ë¡œ ìœ„ì¹˜ */
            left: 240px;  /* ì´ë¯¸ì§€ ì˜¤ë¥¸ìª½ìœ¼ë¡œ ìœ„ì¹˜ */
            font-size: 20px;
            color: #000000;
        }
        .header .menu a {
            text-decoration: none;
            color: #000000;
            font-weight: bold;
            transition: color 0.3s;
        }
        .header .menu a:hover {
            color: #808080;
        }
        .banner-container {
            position: relative;
            width: 100%;
            text-align: center;
        }
        .banner img {
            width: 100%;
            max-height: 250px;
            object-fit: cover;
        }
        .banner-text {
            position: absolute;
            top: 40%;
            left: 50%;
            transform: translate(-50%, -50%);
            color: white;
            font-size: 40px;
            font-weight: bold;
            white-space: nowrap;
        }
        .banner-subtext {
            position: absolute;
            top: 70%;
            left: 50%;
            transform: translate(-50%, -50%);
            color: white;
            font-size: 18px;
            font-weight: normal;
            white-space: nowrap;
        }
        .multiselect-container {
            margin-top: 10px; /* ë°°ë„ˆì™€ì˜ ê°„ê²© */
        }
        .stMultiSelect [data-baseweb="tag"] {
            background-color: #7760FC !important;
            color: white !important;
            border-radius: 5px;
            padding: 5px 10px;
        }
        .divider {
            margin-top: 20px;
            border-top: 1px solid rgba(211, 211, 211, 0.5);
            margin-bottom: 20px;
        }

        div[data-baseweb="tab-list"] button {
            color: black !important; /* ê¸°ë³¸ í…ìŠ¤íŠ¸ ìƒ‰ìƒ */
            border-bottom: 2px solid transparent !important; /* ê¸°ë³¸ ì•„ë˜ ì„  ìˆ¨ê¸°ê¸° */
            padding-bottom: 5px !important;
            transition: none !important; /* ì• ë‹ˆë©”ì´ì…˜ íš¨ê³¼ ì œê±° */
        }

        /* ì„ íƒëœ íƒ­ ìŠ¤íƒ€ì¼ */
        div[data-baseweb="tab-list"] button[aria-selected="true"] {
            color: #7760FC !important;  /* ì„ íƒëœ íƒ­ì˜ í…ìŠ¤íŠ¸ ìƒ‰ìƒ */
            border-bottom: 3px solid #7760FC !important;  /* ì„ íƒëœ íƒ­ ì•„ë˜ ì„  ìƒ‰ìƒ */
            margin-bottom: -2px !important; /* í•˜ë‹¨ì— ë‚¨ëŠ” ë¹¨ê°„ìƒ‰ ì œê±° */
            transition: none !important; /* ì• ë‹ˆë©”ì´ì…˜ íš¨ê³¼ ì œê±° */
        }

        /* ê¸°ë³¸ ì• ë‹ˆë©”ì´ì…˜ íš¨ê³¼ë¥¼ ì œê±°í•˜ì—¬ ìƒ‰ìƒì´ ëŠë¦¬ê²Œ ë³€ê²½ë˜ëŠ” ë¬¸ì œ í•´ê²° */
        div[data-baseweb="tab-highlight"] {
            background-color: #7760FC !important; /* ì• ë‹ˆë©”ì´ì…˜ ìƒ‰ìƒì„ íƒ­ê³¼ ë™ì¼í•˜ê²Œ ë³€ê²½ */
        }

        body { background-color: white; }
        .title { font-size: 28px; font-weight: bold; margin-bottom: 0px; }
        .subtitle { font-size: 14px; color: grey; margin-top: 2px; }
        .growth-box {
            display: inline-block;
            padding: 5px 15px;
            border-radius: 20px;
            font-size: 18px;
            font-weight: bold;
        }
        .button { background-color: #8A5CF6; color: white; font-size: 16px; padding: 10px; border-radius: 10px; text-align: center; display: inline-block; }
        .growth-icon { font-size: 20px; vertical-align: middle; margin-right: 5px; }
        .growth-positive { background-color: #FDECEC; color: #E14C4C; }
        .growth-negative { background-color: #E3F2FD; color: #1976D2; }
        .rounded-box { width: 100%; border-radius: 10px; padding: 10px; background-color: #F8F8F8; margin-bottom: 20px; position: relative; }
        /* 'help' style */
        .help-text {
            position: absolute;
            right: 10px;
            bottom: 10px;
            font-size: 12px;
            color: grey;
            visibility: hidden;
            opacity: 0;
            transition: opacity 0.3s ease-in-out;
        }
        
        .rounded-box:hover .help-text {
            visibility: visible;
            opacity: 1;
        }
    </style>

"""
st.markdown(header_style, unsafe_allow_html=True)



@st.cache_resource
def init_vector_store():
    # 1. Create a Weaviate client
    client = weaviate.Client(
        url=weaviate_url,
        auth_client_secret=weaviate.auth.AuthApiKey(api_key=weaviate_api_key)
    )

    # 2. Initialize the embeddings
    embedding = OpenAIEmbeddings(api_key=openai_api_key)

    # 3. Define the index name and text key
    index_name = "JobDetails"
    text_key = "page_content"

    # 4. Create the vector store
    vector_store = Weaviate(
        client,
        index_name=index_name,
        text_key=text_key,
        embedding=embedding,
        by_text=False
    )

    # 5. (Optional) Load and index documents if you need to do it here
    #    Or you can do it outside once, and not repeat it every time.
    documents = []
    with open("/Users/aria/Downloads/combined_output.json", "r", encoding="utf-8") as f:
        jobs = json.load(f)
        for job in jobs:
            page_content = (
                f"Job Name: {job['Job_name']}\n"
                f"Company: {job['Company_name']}\n"
                f"Region: {job['Region']}\n"
                f"Company Keywords: {job['Company_keyword']}\n"
                f"Job Description Keywords: {job['JD_keyword']}\n"
                f"Requirements Keywords: {job['Requirements_keyword']}\n"
                f"Career Field: {job['career_field']}"
            )
            metadata = {
                "Company_name": job["Company_name"],
                "Region": job["Region"],
                "career_field": job["career_field"],
            }
            documents.append(Document(page_content=page_content, metadata=metadata))

    vector_store.add_documents(documents)
    return vector_store


@st.cache_resource
def get_friendli_client():
    # Create a Friendli client using the OpenAI interface.
    client = OpenAI(
        base_url="https://inference.friendli.ai/v1",
        api_key=friendli_token
    )
    return client



# -------------------------------
# Chat function (streaming)
# -------------------------------
def chat_function(message, history):
    """
    Given a user message and chat history (a list of (user, bot) tuples),
    search for relevant documents, prepare the context, and stream the response.
    This function yields incremental output.
    """
    vector_store = init_vector_store()
    friendli_client = get_friendli_client()

    # Retrieve relevant documents (k=3)
    relevant_docs = vector_store.similarity_search(message, k=3)
    retrieved_context = "\n\n".join([doc.page_content for doc in relevant_docs])

    # Prepare the conversation messages for the LLM.
    messages = [{"role": "system", "content": f"Context from relevant job postings:\n{retrieved_context}"}]
    for user_msg, bot_msg in history:
        messages.append({"role": "user", "content": user_msg})
        messages.append({"role": "assistant", "content": bot_msg})
    messages.append({"role": "user", "content": message})

    # Request a streaming completion.
    chat_stream = friendli_client.chat.completions.create(
        model="meta-llama-3.1-70b-instruct",
        messages=messages,
        temperature=0.7,
        stream=True
    )

    answer = ""
    for chunk in chat_stream:
        delta = chunk.choices[0].delta
        content = delta.content if delta.content is not None else ""
        answer += content
        yield answer
#####################################################################################
def average_colors(color_list):
    """ ì—¬ëŸ¬ ê°œì˜ HEX ìƒ‰ìƒì„ ë°›ì•„ì„œ í‰ê·  ìƒ‰ìƒì„ ë°˜í™˜ """
    rgb_values = [[int(c[i:i+2], 16) for i in (1, 3, 5)] for c in color_list]
    avg = [sum(channel) // len(channel) for channel in zip(*rgb_values)]
    return f'#{avg[0]:02X}{avg[1]:02X}{avg[2]:02X}'

def N_average_colors(color_list, weight_list):
    """ ì—¬ëŸ¬ ê°œì˜ HEX ìƒ‰ìƒê³¼ ê·¸ì— ëŒ€í•œ ê°€ì¤‘ì¹˜ë¥¼ ë°›ì•„ì„œ ìƒ‰ìƒì„ ë³´ê°„í•˜ì—¬ ë°˜í™˜ """
    rgb_values = [[int(c[i:i+2], 16) for i in (1, 3, 5)] for c in color_list]
    weighted_rgb = [sum(c * w for c, w in zip(channel, weight_list)) // sum(weight_list) for channel in zip(*rgb_values)]
    return f'#{weighted_rgb[0]:02X}{weighted_rgb[1]:02X}{weighted_rgb[2]:02X}'

# ì„¸ì…˜ ìƒíƒœì— color_scheme ì´ˆê¸°í™”
if 'color_scheme' not in st.session_state:
    st.session_state.color_scheme = {
        "Back end": "#21DDB8",    # Teal
        "Front end": "#00C7F2",   # Yellow
        "AI": "#695CFB",          # Red-Orange
        "Data": "#FFC246",        # Deep Red
    }

# Big Data/AI ìƒ‰ìƒ = Dataì™€ AI ìƒ‰ìƒì˜ ì¤‘ê°„ìƒ‰
color_DataAI= average_colors([
    st.session_state.color_scheme["Data"], 
    st.session_state.color_scheme["AI"]
])

# ALL ìƒ‰ìƒ = 4ê°œ ì§ì¢…ì˜ í‰ê· ìƒ‰
color_all = average_colors([
    st.session_state.color_scheme["Back end"],
    st.session_state.color_scheme["Front end"],
    st.session_state.color_scheme["AI"],
    st.session_state.color_scheme["Data"]
])

# ì‚¬ì´ë“œë°”ì— ìƒ‰ìƒ ì„ íƒê¸° ì¶”ê°€
st.sidebar.title("ìƒ‰ìƒ ì„¤ì •")
for job_category in st.session_state.color_scheme.keys():
    st.session_state.color_scheme[job_category] = st.sidebar.color_picker(
        f"{job_category} ìƒ‰ìƒ",
        st.session_state.color_scheme[job_category]
    )

# Plotly ì°¨íŠ¸ì— ì‚¬ìš©í•  ìƒ‰ìƒ ë¦¬ìŠ¤íŠ¸
PLOTLY_COLORS = list(st.session_state.color_scheme.values())

# CSV íŒŒì¼ ì½ê¸° (ì‚¬ìš©ìê°€ ì—…ë¡œë“œí•œ íŒŒì¼ë¡œ ë°”ê¿”ì£¼ì„¸ìš”)
file_path = "data/tech_keywords_combined.csv"
data = pd.read_csv(file_path)

# ì˜ˆì‹œë¡œ ì‚¬ìš©ìê°€ ì„ íƒí•œ ê¸°ìˆ  ë¦¬ìŠ¤íŠ¸
selected_skills = ["Python", "AWS", "React", "SQL", "Node.js"]

# ì§ë¬´ë³„ ê°€ì¤‘ì¹˜ ê³„ì‚° í•¨ìˆ˜
def calculate_job_fitness(selected_skills, data):
    job_fitness = {'AI': 0, 'Back end': 0, 'Front end': 0, 'Data': 0}
    total_scores = {'AI': 0, 'Back end': 0, 'Front end': 0, 'Data': 0}

    # ëª¨ë“  ê¸°ìˆ ì— ëŒ€í•œ ì´í•© ê³„ì‚° (ê³ ì •ëœ ê¸°ì¤€ì„ ìœ„í•´)
    for index, row in data.iterrows():
        total_scores['AI'] += row['AI']
        total_scores['Back end'] += row['Back end']
        total_scores['Front end'] += row['Front end']
        total_scores['Data'] += row['Data']

    for skill in selected_skills:
        skill_data = data[data['Keyword'] == skill]
        if not skill_data.empty:
            job_fitness['AI'] += skill_data['AI'].values[0]
            job_fitness['Back end'] += skill_data['Back end'].values[0]
            job_fitness['Front end'] += skill_data['Front end'].values[0]
            job_fitness['Data'] += skill_data['Data'].values[0]

    # ë¹„ìœ¨ ê³„ì‚° (ì „ì²´ ê¸°ìˆ  ëŒ€ë¹„ %)
    for key in job_fitness.keys():
        if total_scores[key] > 0:
            job_fitness[key] = (job_fitness[key] / total_scores[key]) * 100

    return job_fitness


# ë¡œì»¬ ì´ë¯¸ì§€ ê²½ë¡œ
image_path = "/Users/gyun/Desktop/ì„œìš¸ëŒ€/ì‹œê°í™”/ì‹œê°í™”/stream_Job/image/wanted.png"

# ë°°ë„ˆ ì´ë¯¸ì§€ ê²½ë¡œ
banner_image_path = "/Users/gyun/Desktop/ì„œìš¸ëŒ€/ì‹œê°í™”/ì‹œê°í™”/stream_Job/image/banner.png"

logo_image_path = "/Users/gyun/Desktop/ì„œìš¸ëŒ€/ì‹œê°í™”/ì‹œê°í™”/stream_Job/image/logo.png"

# ë¡œì»¬ ì´ë¯¸ì§€ë¥¼ Base64ë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜
def image_to_base64(image_path):
    with open(image_path, "rb") as img_file:
        return base64.b64encode(img_file.read()).decode()



# Base64ë¡œ ë³€í™˜ëœ ì´ë¯¸ì§€ ê²½ë¡œ
base64_image = image_to_base64(image_path)
banner_image = image_to_base64(banner_image_path)

# í—¤ë”ì— ë¡œì»¬ ì´ë¯¸ì§€ ì¶”ê°€
st.markdown(f"""
    <div class="header">
        <div class="logo">
            <!-- ì´ë¯¸ì§€ í´ë¦­ ê°€ëŠ¥í•œ ë§í¬ (í˜„ì¬ ì°½ì—ì„œ ì—´ë¦¼) -->
            <a href="https://www.wanted.co.kr/" target="_self">
                <img src="data:image/png;base64,{base64_image}">
            </a>
        </div>
        <div class="menu">
            <a href="https://www.wanted.co.kr/wdlist" target="_self">â‰¡ì±„ìš©</a>
            <a href="https://www.wanted.co.kr/events" target="_self">ì»¤ë¦¬ì–´</a>
            <a href="https://social.wanted.co.kr/community" target="_self">ì†Œì…œ</a>
            <a href="https://www.wanted.co.kr/cv/list" target="_self">ì´ë ¥ì„œ</a>
            <a href="https://www.wanted.co.kr/gigs/experts" target="_self">í”„ë¦¬ëœì„œ</a>
            <a href="https://www.wanted.co.kr/" target="_self">ë”ë³´ê¸°</a>
        </div>
    </div>
    <div class="banner-container">
        <img class="banner" src="data:image/png;base64,{banner_image}">
        <div class="banner-text">í•™ìŠµ ê¸°ìˆ ì„ ê¸°ë°˜ìœ¼ë¡œ<br>ì§êµ°/ê¸°ìˆ  ì¶”ì²œì„ í™•ì¸í•´ ë³´ì„¸ìš”!</div>
        <div class="banner-subtext">í•™ìŠµ í•˜ì‹  ê¸°ìˆ ì„ ê¸°ë°˜ìœ¼ë¡œ ìƒì„¸ ì§êµ°ì„ ì¶”ì²œ ë°›ê³ <br>ì·¨ì—…ì— ìœ ë¦¬í•œ ê¸°ìˆ  ì¶”ì²œê¹Œì§€ ë°›ì•„ë³´ì„¸ìš”!</div>
    </div>
""", unsafe_allow_html=True)

st.markdown('<div class="multiselect-container">', unsafe_allow_html=True)


tab2, tab1, tab3, tab4 = st.tabs(["ëŒ€ì‹œë³´ë“œ", "ì§ë¬´/ê¸°ìˆ  ì¶”ì²œ", "ìœ„ì¹˜ë³„ ê³µê³  ìˆ˜", "ì±—ë´‡"])

with tab1:
    
    # 'ì§ë¬´' í…ìŠ¤íŠ¸ ì¶”ê°€ (ì™„ì „íˆ ë¶™ì´ê¸°)
    st.markdown("<h4 style='font-size:40px; font-weight:bold; margin-bottom: 0px;'>ê¸°ìˆ ì„ ì„ íƒí•˜ì„¸ìš”.</h4>", unsafe_allow_html=True)

    # ê¸°ìˆ  ì„ íƒ ë©€í‹°ì…€ë ‰íŠ¸
    selected_skills_input = st.multiselect(
        " ",
        options=data['Keyword'].tolist(),
        default=selected_skills,
        help="ì›í‹°ë“œ 2025/02/25ê¹Œì§€ì˜ ë°ì´í„°ì…ë‹ˆë‹¤."
    )
    # íšŒìƒ‰ ì„  ì¶”ê°€
    st.markdown('<div class="divider"></div>', unsafe_allow_html=True)


    # ì§ë¬´ ì í•©ë„ ê³„ì‚°
    job_fitness = calculate_job_fitness(selected_skills_input, data)
    recommended_job = max(job_fitness, key=job_fitness.get).replace('_ì§ì¢…', '')


    # ì¤‘ì•™ ì •ë ¬ì„ ìœ„í•œ ì»¬ëŸ¼ ë°°ì¹˜
    job1, job2, job3 = st.columns([1, 0.02, 1])  # ì¤‘ê°„ ê°„ê²©ì„ 0.02ë¡œ ì¶•ì†Œ

    with job1:
        st.markdown(
            """
            <div style='display: flex; flex-direction: column; align-items: flex-end; text-align: right; padding-right: 10px;'>
                <p style='color: gray; font-size: 14px; margin-bottom: 5px;'>ê¸°ìˆ ì„ ê¸°ë°˜ìœ¼ë¡œ í•œ</p>
                <p style='color: black; font-size: 28px; font-weight: bold; margin-top: 0px;'>ì¶”ì²œ ì§ë¬´ëŠ”?</p>
            </div>
            """,
            unsafe_allow_html=True
        )

    with job2:
        st.markdown(
            """
            <div style='width: 1px; height: 80px; background-color: #D3D3D3; margin: auto;'></div>
            """, 
            unsafe_allow_html=True
        ) 

    with job3:
        st.markdown(
            f"""
            <div style='display: flex; flex-direction: column; align-items: flex-start; text-align: left; padding-left: 10px;'>
                <p style='color: gray; font-size: 14px; margin-bottom: 5px;'>ê¸°ìˆ  ê¸°ë°˜ ì í•©í•œ ì§ë¬´ëŠ”?</p>
                <p style='color: black; font-size: 28px; font-weight: bold; margin-top: 0px;'>{recommended_job} ì§ë¬´ë¥¼ ì¶”ì²œí•©ë‹ˆë‹¤</p>
            </div>
            """,
            unsafe_allow_html=True
        )

    # íšŒìƒ‰ ì„  ì¶”ê°€
    st.markdown('<div class="divider"></div>', unsafe_allow_html=True)

    # ì¶”ì²œ ê¸°ìˆ  ê³„ì‚° í•¨ìˆ˜
    def recommend_skills(selected_skills, recommended_job, data):
        remaining_skills = data[~data['Keyword'].isin(selected_skills)]
        sorted_skills = remaining_skills.sort_values(by=[recommended_job], ascending=False)
        top_skills = sorted_skills.head(5)[['Keyword', recommended_job]]
        return top_skills

    # ì¶”ì²œ ê¸°ìˆ  ê³„ì‚°
    recommended_skills = recommend_skills(selected_skills_input, recommended_job, data)


    def plot_job_fitness(job_fitness):
        fixed_range = 100
        categories = ["AI", "Back end", "Front end", "Data"]
        values = list(job_fitness.values()) + [job_fitness["AI"]]  # ë§ˆì§€ë§‰ì— AI ì¶”ê°€

        fig = go.Figure()
        fig.add_trace(go.Scatterpolar(
            r=[fixed_range, fixed_range, fixed_range, fixed_range, fixed_range],  # ë§ˆì§€ë§‰ ê°’ ì¶”ê°€
            theta=categories + [categories[0]],  # categoriesì— ì²« ë²ˆì§¸ í•­ëª©ì„ ì¶”ê°€í•˜ì—¬ ì—°ê²°
            fill=None,
            mode='lines',
            line=dict(color="black", width=2),
            showlegend=False
        ))
        fig.add_trace(go.Scatterpolar(
            r=values,
            theta=categories + [categories[0]],  # categoriesì— ì²« ë²ˆì§¸ í•­ëª©ì„ ì¶”ê°€í•˜ì—¬ ì—°ê²°
            fill='toself',
            name='ì§ë¬´ ì í•©ë„',
            marker=dict(color='rgba(0, 102, 204, 0.8)')
        ))
        fig.update_layout(
            polar=dict(
                radialaxis=dict(visible=False),
                angularaxis=dict(showline=False, tickfont=dict(size=14, color="black")),
            ),
            showlegend=False,
            paper_bgcolor='white',
            plot_bgcolor='white',
        )
        return fig


    # ì§ë¬´ ì í•©ë„ ì‹œê°í™”
    col1, col2 = st.columns([1, 1])  # ì§ë¬´ ì í•©ë„ ê·¸ë˜í”„ëŠ” ì™¼ìª½, íˆíŠ¸ë§µì€ ì˜¤ë¥¸ìª½

    with col1:
        # ì§ë¬´ ì í•©ë„ ê·¸ë˜í”„
        st.plotly_chart(plot_job_fitness(job_fitness), use_container_width=True)

    with col2:
        # ê¸°ìˆ  ìŠ¤íƒ ì í•©ë„ íˆíŠ¸ë§µ
        filtered_data = data[data['Keyword'].isin(selected_skills_input)]

        # Total ì»¬ëŸ¼ì´ ìˆëŠ” ê²½ìš° ì œê±°
        if 'Total' in filtered_data.columns:
            heatmap_data = filtered_data.set_index('Keyword').drop(columns=['Total'])
        else:
            heatmap_data = filtered_data.set_index('Keyword')

        if len(heatmap_data) != 0:
            # í–‰ê³¼ ì—´ì„ ë°”ê¾¸ì–´ ì§ë¬´ê°€ yì¶•ì— ì˜¤ë„ë¡ í•¨
            heatmap_data = heatmap_data.transpose()

            # ì§ë¬´ë³„ ê¸°ë³¸ ìƒ‰ìƒ ì„¤ì • (ì›í•˜ëŠ” ìƒ‰ìƒê³¼ ìœ ì‚¬í•˜ê²Œ)
            custom_colors = {
                "Back end": st.session_state.color_scheme.get("Back end", "#21DDB8"),  
                "Front end": st.session_state.color_scheme.get("Front end", "#00C7F2"),
                "AI": st.session_state.color_scheme.get("AI", "#695CFB"),
                "Data": st.session_state.color_scheme.get("Data", "#FFC246")
            }

            # ì›í•˜ëŠ” ì§ë¬´ ìˆœì„œë¡œ ì¬ì •ë ¬ (ë°ì´í„°ì— í•´ë‹¹ ì§ë¬´ê°€ ëª¨ë‘ ì¡´ì¬í•˜ëŠ” ê²½ìš°)
            desired_order = ["AI", "Back end", "Front end", "Data"]
            heatmap_data = heatmap_data.reindex(desired_order)

            # ì „ì²´ ë°ì´í„° ì¤‘ ìµœëŒ€ê°’ (ì •ê·œí™”ë¥¼ ìœ„í•´)
            overall_max = heatmap_data.max().max()

            # ì§ì ‘ ì…€ ë‹¨ìœ„ë¡œ ì‚¬ê°í˜•ì„ ê·¸ë ¤ ê° ì§ë¬´ë³„ ê¸°ë³¸ ìƒ‰ìƒê³¼ ê°’ì˜ ë¹„ìœ¨ì— ë”°ë¥¸ ì§„í•˜ê¸°ë¥¼ í‘œí˜„
            nrows, ncols = heatmap_data.shape
            fig, ax = plt.subplots(figsize=(5, 3))
            for i, job in enumerate(heatmap_data.index):
                for j, skill in enumerate(heatmap_data.columns):
                    value = heatmap_data.loc[job, skill]
                    norm = value / overall_max if overall_max != 0 else 0  # 0~1 ë²”ìœ„ë¡œ ì •ê·œí™”
                    base_color = custom_colors.get(job, "#FFFFFF")
                    base_rgb = mcolors.to_rgb(base_color)
                    # í°ìƒ‰ê³¼ ê¸°ë³¸ ìƒ‰ìƒ ì‚¬ì´ë¥¼ ì„ í˜• ë³´ê°„: norm=0ì´ë©´ í°ìƒ‰, norm=1ì´ë©´ ê¸°ë³¸ ìƒ‰ìƒ
                    blended_rgb = tuple((1 - norm) * 1 + norm * base for base in base_rgb)
                    blended_hex = mcolors.to_hex(blended_rgb)
                    # ì…€ ì‚¬ê°í˜• ê·¸ë¦¬ê¸° (edgecolorë¡œ íšŒìƒ‰ í…Œë‘ë¦¬ ì¶”ê°€)
                    rect = plt.Rectangle((j, i), 1, 1, facecolor=blended_hex, edgecolor='grey')
                    ax.add_patch(rect)
                    # ì…€ ì¤‘ì•™ì— ê°’ í‘œì‹œ (ì›í•˜ëŠ” ê²½ìš° ì£¼ì„ í•´ì œ)
                    ax.text(j + 0.5, i + 0.5, f"{value:.0f}", ha="center", va="center", fontsize=9)

            # ì¶• ì„¤ì •: xì¶•ì€ ê¸°ìˆ (Keyword), yì¶•ì€ ì§ë¬´
            ax.set_xlim(0, ncols)
            ax.set_ylim(0, nrows)
            ax.set_xticks([x + 0.5 for x in range(ncols)])
            ax.set_yticks([x + 0.5 for x in range(nrows)])
            ax.set_xticklabels(heatmap_data.columns, rotation=45, ha="right")
            ax.set_yticklabels(heatmap_data.index, rotation=0)
            ax.invert_yaxis()  # ìœ„ìª½ë¶€í„° ì²« ë²ˆì§¸ í–‰ì´ ë‚˜ì˜¤ë„ë¡
            ax.tick_params(axis='both', labelsize=10)
            ax.set_xlabel('')
            ax.set_ylabel('')
            plt.tight_layout()
            st.pyplot(fig)

    # ì¤‘ì•™ ì •ë ¬ì„ ìœ„í•´ ì¶”ê°€ CSS ìŠ¤íƒ€ì¼
    # st.markdown("""
    #     <style>
    #         .stColumn {
    #             display: flex;
    #             justify-content: center;
    #             align-items: center;  /* ì„¸ë¡œë¡œ ì¤‘ì•™ ì •ë ¬ */
    #             height: 100%;  /* ë†’ì´ë¥¼ 100%ë¡œ ì„¤ì •í•˜ì—¬ ì„¸ë¡œ ì •ë ¬ì´ ì œëŒ€ë¡œ ì´ë£¨ì–´ì§€ê²Œ í•¨ */
    #         }
    #     </style>
    # """, unsafe_allow_html=True)

    # íšŒìƒ‰ ì„  ì¶”ê°€
    st.markdown('<div class="divider"></div>', unsafe_allow_html=True)

    # ìƒìœ„ 5ê°œ ê¸°ìˆ  ì„ íƒ (ì í•©ë„ ê¸°ì¤€ ì •ë ¬)
    top_skills = recommended_skills.nlargest(5, recommended_job)
    top_skills = top_skills.sort_values(by=recommended_job, ascending=True)
    # í…ìŠ¤íŠ¸ ì„¤ëª… ì¶”ê°€
    st.markdown("""
        <div style="padding: 10px; text-align: center; background-color: #f7f7f7; border-radius: 8px; margin-bottom: 20px;">
            <h3 style="color: #6a1b9a; font-size: 28px;">í•´ë‹¹ ì§ë¬´ì˜ ì¶”ì²œ ê¸°ìˆ </h3>
            <p style="color: #333; font-size: 14px;">ì í•©ë„ì— ë”°ë¼ ì¶”ì²œëœ ìƒìœ„ 5ê°œì˜ ê¸°ìˆ ì„ í™•ì¸í•˜ì„¸ìš”. ê° ê¸°ìˆ ì˜ ì í•©ë„ëŠ” ë°±ë¶„ìœ¨ë¡œ í‘œì‹œë©ë‹ˆë‹¤.</p>
        </div>
    """, unsafe_allow_html=True)

    # ê·¸ë˜í”„ í¬ê¸° ì„¤ì •
    fig, ax = plt.subplots(figsize=(8, 3))  # ì ë‹¹í•œ í¬ê¸°ë¡œ ë„ˆë¹„ëŠ” 8, ë†’ì´ëŠ” 3ìœ¼ë¡œ ì„¤ì •

    # ê°€ë¡œ ë§‰ëŒ€ ê·¸ë˜í”„ ê·¸ë¦¬ê¸°
    bars = ax.barh(top_skills['Keyword'], top_skills[recommended_job], color='#8A5CF6', height=0.4)  # ë§‰ëŒ€ ë†’ì´ ì„¤ì •

    # ê° ë§‰ëŒ€ ìƒë‹¨ ì™¼ìª½ì— ê¸°ìˆ ëª… í‘œì‹œ
    for bar, skill in zip(bars, top_skills['Keyword']):
        ax.text(bar.get_x() + 0.3, bar.get_y() + bar.get_height(), skill,  
                va='bottom', ha='left', fontsize=8, fontweight='bold', color='black')


    # ë§‰ëŒ€ ë‚´ë¶€ ì˜¤ë¥¸ìª½ì— ì í•©ë„ % í‘œì‹œ
    for bar in bars:
        ax.text(bar.get_width() - 1, bar.get_y() + bar.get_height() / 2,
                f"{int(bar.get_width())}%", va='center', ha='right', fontsize=7, color='white')

    # ë¶ˆí•„ìš”í•œ í…Œë‘ë¦¬ ë° ì¶• ì œê±°
    ax.spines['top'].set_visible(False)
    ax.spines['right'].set_visible(False)
    ax.spines['left'].set_visible(False)
    ax.spines['bottom'].set_visible(False)

    # ëˆˆê¸ˆì„  ë° ì¶• ìˆ¨ê¸°ê¸°
    ax.xaxis.set_visible(False)
    ax.yaxis.set_visible(False)

    # tight_layout()ë¡œ ë‚´ë¶€ ìš”ì†Œ ì •ë¦¬
    plt.tight_layout(pad=2.0)  # ê·¸ë˜í”„ ë‚´ë¶€ ìš”ì†Œ ê°„ì˜ ê°„ê²©ì„ ì¡°ì ˆ

    # ê·¸ë˜í”„ ì¶œë ¥
    st.pyplot(fig, use_container_width=False)

with tab2:
    # ë ˆì´ì•„ì›ƒ ì„¤ì •
    grid = st.columns([1.5, 2.5])

    # CSV íŒŒì¼ ë° ë°ì´í„° ì „ì²˜ë¦¬
    # ë°ì´í„° ë¡œë“œ
    tech_data = pd.read_csv("data/tech_keywords_combined.csv")
    seniority_data = pd.read_csv('data/ê²½ë ¥_ë²”ìœ„ë³„_ê³µê³ _ìˆ˜.csv')
    # 'DB'ë¥¼ 'Big Data/AI'ë¡œ ë³€ê²½
    seniority_data['ì§ë¬´'] = seniority_data['ì§ë¬´'].replace('DB', 'Data')

    total_seniority_data = seniority_data.iloc[:, 1:].sum(axis=1)
    file_path = "data/fintech_jobs_final.csv"
    job_monthly_trend, job_growth_rate = preprocess_data(file_path, period=1)

    # ìµœì‹  ì›” ì„±ì¥ë¥  ê°€ì ¸ì˜¤ê¸°
    latest_month = job_growth_rate.index[-1]
    growth_rates = job_growth_rate.loc[latest_month]

    with grid[0]:
        st.markdown("""
        <div class='rounded-box'>
            <h3>í˜„ì¬ ì±„ìš© ì¤‘</h3>
            <div class='help-text'>ì¶œì²˜ : ì›í‹°ë“œ</div>
        </div>
    """, unsafe_allow_html=True)

        # ì „ì²´ ì±„ìš© ê±´ìˆ˜
        total_jobs = int(total_seniority_data.sum())
        
        # ì§ë¬´ë³„ ì´ê³µê³ ìˆ˜ ë„ë„› ì°¨íŠ¸
        fig_donut = px.pie(
            names=seniority_data['ì§ë¬´'],
            values=total_seniority_data,
            color_discrete_sequence=PLOTLY_COLORS,
            hole=0.75,
        )
        
        fig_donut.update_traces(
            textposition='outside',
            textinfo='none',
            hoverinfo='skip',
            rotation=90,
            pull=[0.01] * len(seniority_data),
            marker=dict(
                line=dict(color='white', width=3)
            )
        )
        
        # ì¤‘ì•™ì— ì „ì²´ ê±´ìˆ˜ í…ìŠ¤íŠ¸ ì¶”ê°€
        fig_donut.add_annotation(
            text=f"{total_jobs:,}ê±´<br><span style='font-size:12px'>ì „ì²´ ì±„ìš© ê¸°ì¤€</span>",
            x=0.5,
            y=0.5,
            showarrow=False,
            font=dict(
                size=16,
                family="Arial",
            ),
            xanchor='center',
            yanchor='middle'
        )
        
        fig_donut.update_layout(
            showlegend=True,
            legend=dict(
                orientation="h",
                yanchor="bottom",
                y=-0.3,
                xanchor="center",
                x=0.5
            ),
            margin=dict(t=20, b=20, l=20, r=20),
            height=300,
            paper_bgcolor='rgba(0,0,0,0)',
            plot_bgcolor='rgba(0,0,0,0)',
        )
        

        st.plotly_chart(fig_donut, use_container_width=True)
        
        st.markdown("<div class='rounded-box'><h3>ì§ë¬´ë³„ ì¤‘ìš” í‚¤ì›Œë“œ</h3></div>", unsafe_allow_html=True)
        word_job = st.selectbox("ì§ì¢… ì„ íƒ", ["Back end", "Front end", "AI", "Data"])
        word_mapping = {"Back end": "/Users/gyun/Desktop/ì„œìš¸ëŒ€/ì‹œê°í™”/ì‹œê°í™”/stream_Job/image/image_back.png", 
                        "Front end": "/Users/gyun/Desktop/ì„œìš¸ëŒ€/ì‹œê°í™”/ì‹œê°í™”/stream_Job/image/image_Front.png", 
                        "AI": "/Users/gyun/Desktop/ì„œìš¸ëŒ€/ì‹œê°í™”/ì‹œê°í™”/stream_Job/image/image_AI.png", 
                        "Data": "/Users/gyun/Desktop/ì„œìš¸ëŒ€/ì‹œê°í™”/ì‹œê°í™”/stream_Job/image/image_Data.png"}
        selected_job = word_mapping[word_job]
        st.image(selected_job, caption=word_job)
        
        # ì§ì¢… ë° ê¸°ìˆ  ì»¬ëŸ¼ ì„¤ì •
        job_roles = ["AI", "Back end", "Front end", "Data"]

        # Sankey ì°¨íŠ¸ ë°ì´í„° êµ¬ì„±
        sources, targets, values = [], [], []
        labels = list(tech_data["Keyword"]) + job_roles
        label_map = {label: idx for idx, label in enumerate(labels)}

        # ëœë¤ ìƒ‰ìƒì„ ìƒì„±í•˜ëŠ” í•¨ìˆ˜
        def random_color():
            return f'#{random.randint(0, 255):02X}{random.randint(0, 255):02X}{random.randint(0, 255):02X}'
        
        # ê° ë…¸ë“œì— ëŒ€í•´ ìƒ‰ìƒì„ ì§€ì •
        node_colors = [st.session_state.color_scheme[label] if label in st.session_state.color_scheme else random_color() for label in labels]
    
        for job in job_roles:
            top_techs = tech_data.nlargest(5, job)[["Keyword", job]]
            for _, row in top_techs.iterrows():
                sources.append(label_map[job])
                targets.append(label_map[row["Keyword"]])
                values.append(row[job])
        # Sankey Chart ìƒì„±
        fig_sankey = go.Figure(go.Sankey(
            node=dict(
                pad=15,
                thickness=20,
                line=dict(color="black", width=0.5),
                label=labels,
                color=node_colors  # ìƒ‰ìƒ ì ìš©
            ),
            link=dict(
                source=sources,
                target=targets,
                value=values,
            )
        ))
        st.markdown("<div class='rounded-box'><h3>ì§ë¬´ë³„ ì£¼ìš” ê¸°ìˆ  ì—°ê´€ì„±</h3></div>", unsafe_allow_html=True)
        st.plotly_chart(fig_sankey, use_container_width=True)


    with grid[1]:
        
        st.markdown("""
        <div class='rounded-box'>
            <h3>ì±„ìš© ê·œëª¨ ì„±ì¥ë¥ </h3>
            <div class='help-text'>ì¶œì²˜ : í•€í…Œí¬ í¬í„¸</div>
        </div>
    """, unsafe_allow_html=True)

        def draw_chart(title, data, growth_rate, color):
            df = pd.DataFrame({
                "ì±„ìš©ê¸°ê°„_ì›”": job_monthly_trend.index,
                "ì±„ìš©ê³µê³ ìˆ˜": data
            })

            chart = (
                alt.Chart(df)
                .mark_line(
                    color=color,
                    size=2,
                    interpolate='basis'
                )
                .encode(
                    x=alt.X("ì±„ìš©ê¸°ê°„_ì›”", title="", axis=alt.Axis(labelAngle=0)),
                    y=alt.Y("ì±„ìš©ê³µê³ ìˆ˜", title="", scale=alt.Scale(domain=[0, df['ì±„ìš©ê³µê³ ìˆ˜'].max() + 100])),
                    tooltip=["ì±„ìš©ê¸°ê°„_ì›”", "ì±„ìš©ê³µê³ ìˆ˜"]
                )
            )

            growth_class = "growth-positive" if growth_rate > 0 else "growth-negative"
            growth_icon = "ğŸ“ˆ" if growth_rate > 0 else "ğŸ“‰"

            growth_html = f"""
            <div style="display: flex; justify-content: space-between; align-items: center;">
                <div>
                    <div class='title'>{title}</div>
                    <div class='subtitle'>{latest_month} ê¸°ì¤€</div>
                </div>
                <div class='growth-box {growth_class}'><span class='growth-icon'>{growth_icon}</span>{growth_rate:.1f}%</div>
            </div>
            """

            st.markdown(growth_html, unsafe_allow_html=True)
            st.altair_chart(chart, use_container_width=True)

        # ì„±ì¥ë¥  ê¸°ì¤€ ê¸°ê°„ ì„ íƒ
        growth_period = st.selectbox("", ["1ê°œì›”", "3ê°œì›”", "6ê°œì›”", "12ê°œì›”"])
        period_mapping = {"1ê°œì›”": 1, "3ê°œì›”": 3, "6ê°œì›”": 6, "12ê°œì›”": 12}
        selected_period = period_mapping[growth_period]

        job_monthly_trend, job_growth_rate = preprocess_data(file_path, period=selected_period)
        growth_rates = job_growth_rate.loc[latest_month]
        
        m_col1, m_col2 = st.columns(2)
        m_col3, m_col4 = st.columns(2)

        with m_col1:
            draw_chart("Backend", job_monthly_trend["Back end"], growth_rates["Back end"], st.session_state.color_scheme["Back end"])

        with m_col2:
            draw_chart("Frontend", job_monthly_trend["Front end"], growth_rates["Front end"], st.session_state.color_scheme["Front end"])

        with m_col3:
            draw_chart("Big Data/AI", job_monthly_trend["Big Data/AI"], growth_rates["Big Data/AI"], color_DataAI)  # ë²„íŠ¼ í´ë¦­ ì‹œ í˜ì´ì§€ë¥¼ ìƒˆë¡œ ê³ ì¹¨í•˜ì—¬ ë‹¤ë¥¸ ì„ íƒì´ ë°˜ì˜ë˜ë„ë¡ í•¨)

        with m_col4:
            draw_chart("ALL", job_monthly_trend["ALL"], growth_rates["ALL"], color_all)

        seniority_data['ì´í•©'] = seniority_data.iloc[:, 1:].sum(axis=1)
        seniority_data_melted = seniority_data.melt(id_vars=['ì§ë¬´', 'ì´í•©'], var_name='ì—°ì°¨', value_name='ì„ í˜¸ë„')
        seniority_data_melted['ë°±ë¶„ìœ¨'] = (seniority_data_melted['ì„ í˜¸ë„'] / seniority_data_melted['ì´í•©']) * 100

        st.markdown("""
            <div class='rounded-box' style="margin-top: 27px;">
                <h3>ì§ë¬´/ê¸°ìˆ  ë„¤íŠ¸ì›Œí¬</h3>
            </div>
        """, unsafe_allow_html=True)

        # Big Data/AI ìƒ‰ìƒ = Dataì™€ AI ìƒ‰ìƒì˜ ì¤‘ê°„ìƒ‰
        color_DataAI = N_average_colors([
            st.session_state.color_scheme["Data"], 
            st.session_state.color_scheme["AI"]
        ], [1, 1])  # ìƒ‰ìƒ ë¹„ìœ¨ 1:1

        # [1] CSV íŒŒì¼ ì½ê¸°
        csv_file_name = "data/tech_keywords_combined.csv"

        df = pd.read_csv(csv_file_name)


        columns = df.columns.tolist()
    
        # ì²« ì—´: ê¸°ìˆ  í‚¤ì›Œë“œ
        keyword_col = columns[0]   # ì˜ˆ: 'Keyword'
        # ë‚˜ë¨¸ì§€ ì—´: ì§ë¬´ (ì˜ˆ: ['AI', 'Back end', 'Front end', 'Data'])
        job_roles = columns[1:]

        # [2] NetworkX ê·¸ë˜í”„ ìƒì„±
        G = nx.Graph()

        def get_color_by_freq(role_freq_dict):
            """ëª¨ë“  ì§ë¬´ì˜ ë¹ˆë„ë¥¼ ë°˜ì˜í•˜ì—¬ ìƒ‰ìƒ í˜¼í•©"""
            if not role_freq_dict:
                return "lightgray"
            
            # ë¹ˆë„ 0ì´ ì•„ë‹Œ ì§ë¬´ë§Œ ì„ íƒ
            valid_roles = {role: freq for role, freq in role_freq_dict.items() if freq > 0}

            # ëª¨ë“  ê´€ë ¨ ì§ë¬´ì˜ ìƒ‰ìƒê³¼ ë¹ˆë„ë¥¼ ë°˜ì˜í•˜ì—¬ í˜¼í•©
            colors = [st.session_state.color_scheme[role] for role in valid_roles.keys()]
            weights = list(valid_roles.values())  # ë¹ˆë„ë¥¼ ê°€ì¤‘ì¹˜ë¡œ ì‚¬ìš©

            return N_average_colors(colors, weights)

        # [3] ì§ë¬´ ë…¸ë“œ ì¶”ê°€ (group ì†ì„± ì œê±°)
        for role in job_roles:
            dark_color = st.session_state.color_scheme.get(role, "gray")

            G.add_node(
                role,
                label=role,
                shape="dot",
                color=dark_color,
                size=53,
                font=dict(size=30),
                mass=5
            )

        # [4] ê¸°ìˆ  ë…¸ë“œ + ì—£ì§€ ì¶”ê°€ (group ì†ì„± ì œê±°)
        for idx, row in df.iterrows():
            skill = row[keyword_col]

            # ì§ë¬´ë³„ ë¹ˆë„ ë”•ì…”ë„ˆë¦¬
            role_freq_dict = {r: row[r] for r in job_roles}
            total_freq = sum(role_freq_dict.values())

            # ê¸°ìˆ  ë…¸ë“œ ìƒ‰ìƒ: ê°€ì¥ ë§ì´ ì–¸ê¸‰ëœ ì§ë¬´ ê¸°ì¤€
            node_color = get_color_by_freq(role_freq_dict)

            # íˆ´íŒ ("/"ë¡œ êµ¬ë¶„)
            tooltip_lines = []
            for (r, f) in sorted(role_freq_dict.items(), key=lambda x: x[1], reverse=True)[:2]:
                pct = (f / total_freq * 100) if total_freq > 0 else 0
                tooltip_lines.append(f"{r}: {f} ({pct:.2f}%)")
            tooltip_text = " / ".join(tooltip_lines)

            # ê¸°ìˆ  ë…¸ë“œ í¬ê¸° ê³„ì‚°
            base_size = 10 + total_freq * 0.5
            node_size = base_size * 0.4

            # ê¸°ìˆ  ë…¸ë“œ ì¶”ê°€ (group ì œê±°)
            G.add_node(
                skill,
                label=skill,
                shape="dot",
                color=node_color,
                size=node_size,
                font=dict(size=30),
                title=tooltip_text
            )

            # freq > 0 ì¸ ì§ë¬´ì—ë§Œ ì—£ì§€ ì—°ê²°
            for role in job_roles:
                freq = role_freq_dict[role]
                if freq > 0:
                    edge_color = st.session_state.color_scheme.get(role, "lightgray")
                    # ê°€ì¤‘ì¹˜ê°€ ë†’ì€ ê²½ìš° ë” ì§§ì€ ì—£ì§€ ê¸¸ì´
                    edge_length = max(50, 300 - freq * 10)  # ìµœëŒ€ 300, ìµœì†Œ 50ê¹Œì§€
                    # ì—£ì§€ ì¶”ê°€ (ê°€ì¤‘ì¹˜ì™€ ê¸¸ì´ ì¡°ì •)
                    G.add_edge(
                        skill,
                        role,
                        value=freq * 2,    # ê°€ì¤‘ì¹˜ ê°•í™”
                        color=edge_color,
                        title=f"{skill} â†” {role}: {freq}",
                        length=edge_length  # ì—£ì§€ ê¸¸ì´ ì¶”ê°€
                    )

        # [5] "ì°¨ìˆ˜(degree)ê°€ 1ì¸ ë…¸ë“œ"ì˜ ì—£ì§€ ê¸¸ì´ ë°˜ìœ¼ë¡œ ë§Œë“¤ê¸°
        for node in G.nodes():
            if G.degree(node) == 1:
                edges = list(G.edges(node, data=True))
                if len(edges) == 1:
                    u, v, data_dict = edges[0]
                    data_dict["length"] = 187

        # PyVis ì„¤ì • (ê°„ê²© 2.5ë°°: node_distance=450, spring_length=375 ë“±)
        net = Network(width="100%", height="800px")
        net.repulsion(
            node_distance=350,    # ê¸°ì¡´ 450 -> 350 (ì¡°ê¸ˆ ë” ê°€ê¹Œì›Œì§€ë„ë¡)
            central_gravity=0.2,  # ê¸°ì¡´ 0.1 -> 0.2 (ê´€ë ¨ëœ ë…¸ë“œë¼ë¦¬ ë°€ì§‘)
            spring_length=300,    # ê¸°ì¡´ 375 -> 300 (ì—°ê²°ëœ ë…¸ë“œë“¤ ë” ê°€ê¹Œì´)
            spring_strength=0.15, # ê¸°ì¡´ 0.05 -> 0.15 (ê°€ì¤‘ì¹˜ ë†’ì€ ë…¸ë“œë¼ë¦¬ ë°€ì°©)
            damping=0.85
        )

        # NetworkX -> PyVis
        net.from_nx(G)

        # HTML ì €ì¥ í›„ Streamlitì— ì„ë² ë“œ
        net.save_graph("network.html")
        with open("network.html", "r", encoding="utf-8") as f:
            html_data = f.read()

        
        # Streamlitì— ê·¸ë˜í”„ ì„ë² ë“œ (ê°€ë¡œë¡œ ë” ë„“ê²Œ ì„¤ì •)
        html(f"""
        <div style="display: flex; justify-content: center; align-items: center; height: 100vh;">
            {html_data}
        </div>
        """, height=400, width=950, scrolling=True)


    
    st.markdown("<div class='rounded-box'><h3>ì§ë¬´ë³„ ì—°ì°¨ ì„ í˜¸ë„</h3></div>", unsafe_allow_html=True)
    fig_scatter = px.scatter(
        seniority_data_melted, 
        x='ì—°ì°¨', 
        y='ì„ í˜¸ë„', 
        color='ì§ë¬´',
        size='ì„ í˜¸ë„',
        labels={'ë°±ë¶„ìœ¨': 'ë°±ë¶„ìœ¨ (%)', 'ì§ë¬´': 'ì§ë¬´ ë¶„ì•¼'},
        hover_data={'ë°±ë¶„ìœ¨': ':.2f'},
        color_discrete_sequence=PLOTLY_COLORS
    )
    st.plotly_chart(fig_scatter, use_container_width=True)
    

with tab3:
    # CSV íŒŒì¼ ê²½ë¡œ ì„¤ì • (ì˜ˆì‹œë¡œ íŒŒì¼ëª… 'map_data.csv' ì‚¬ìš©)
    df = pd.read_csv('data/map_data.csv')

    # ë°ì´í„° ì „ì²˜ë¦¬: ì§€ì—­ë³„ ì§ì¢…ì˜ ê°œìˆ˜ ê³„ì‚° (ê³µê³  ìˆ˜ ê³„ì‚°)
    job_count = df.groupby(['ì§€ì—­', 'ì§ì¢…']).size().reset_index(name='ê³µê³  ìˆ˜')

    # ê° ì§€ì—­ì˜ ì´ ê³µê³  ìˆ˜ ê³„ì‚°
    total_job_count = df.groupby('ì§€ì—­').size().reset_index(name='ì´ ê³µê³  ìˆ˜')

    # ì§ì¢…ë³„ ê³µê³  ìˆ˜ë¥¼ ê³„ì‚°í•  ë•Œ, 'ê³µê³  ìˆ˜'ì™€ 'ì´ ê³µê³  ìˆ˜'ì˜ íƒ€ì…ì„ intë¡œ ë³€í™˜
    job_count['ê³µê³  ìˆ˜'] = job_count['ê³µê³  ìˆ˜'].astype(int)
    total_job_count['ì´ ê³µê³  ìˆ˜'] = total_job_count['ì´ ê³µê³  ìˆ˜'].astype(int)

    # ì˜ˆì‹œ: ê° ì§€ì—­ì˜ ìœ„ë„, ê²½ë„ ì •ë³´ (ì¶”ê°€/ìˆ˜ì • í•„ìš”)
    location_coords = {
        'ì„œìš¸ ê°•ë‚¨êµ¬': [37.5173, 127.0473],
        'ì„œìš¸ ì„œì´ˆêµ¬': [37.4834, 127.0322],
        'ê²½ê¸° ì„±ë‚¨ì‹œ': [37.4386, 127.1377],
        'ì„œìš¸ ë§ˆí¬êµ¬': [37.5663, 126.9000],
        'ì„œìš¸ ì„±ë™êµ¬': [37.5633, 127.0425],
        'ì„œìš¸ ì˜ë“±í¬êµ¬': [37.5267, 126.8978],
        'ì„œìš¸ ì¤‘êµ¬': [37.5636, 126.9970],
        'ì„œìš¸ ì†¡íŒŒêµ¬': [37.5146, 127.1054],
        'ì„œìš¸ êµ¬ë¡œêµ¬': [37.4952, 126.8817],
        'ì„œìš¸ ê´€ì•…êµ¬': [37.4780, 126.9517],
        'ì„œìš¸ ê¸ˆì²œêµ¬': [37.4582, 126.8984],
        'ì„œìš¸ ì¢…ë¡œêµ¬': [37.5707, 126.9812],
        'ì„œìš¸ ìš©ì‚°êµ¬': [37.5326, 126.9903],
        'ì„œìš¸ ê°•ì„œêµ¬': [37.5482, 126.8490],
        'ì¸ì²œ ì—°ìˆ˜êµ¬': [37.4133, 126.6500],
        'ê²½ê¸° ì•ˆì–‘ì‹œ': [37.3910, 126.9248],
        'ëŒ€ì „ ìœ ì„±êµ¬': [36.3730, 127.3660],
        'ê²½ê¸° ê³¼ì²œì‹œ': [37.4445, 126.9978],
        'ì„œìš¸ ê´‘ì§„êµ¬': [37.5399, 127.0827],
        'ê²½ê¸° ìš©ì¸ì‹œ': [37.2415, 127.1780],
        'ë¶€ì‚° í•´ìš´ëŒ€êµ¬': [35.1645, 129.1603],
        'ì„œìš¸ ë™ì‘êµ¬': [37.5113, 126.9404],
        'ê²½ê¸° ìˆ˜ì›ì‹œ': [37.2636, 127.0286],
        'ê²½ê¸° ê³ ì–‘ì‹œ': [37.6487, 126.8357],
        'ë¶€ì‚° ë¶€ì‚°ì§„êµ¬': [35.1591, 129.0630],
        'ì¶©ë‚¨ ì²œì•ˆì‹œ': [36.8057, 127.1390],
        'ì„œìš¸ ë™ëŒ€ë¬¸êµ¬': [37.5743, 127.0434],
        'ì„œìš¸ ê°•ë™êµ¬': [37.5302, 127.1235],
        'ê²½ê¸° í™”ì„±ì‹œ': [37.2045, 127.0075],
        'ê²½ê¸° íŒŒì£¼ì‹œ': [37.7521, 126.7732],
        'ì„œìš¸ ì„œëŒ€ë¬¸êµ¬': [37.5822, 126.9368],
        'ê²½ê¸° êµ°í¬ì‹œ': [37.3597, 126.9261],
        'ê²½ê¸° ê´‘ì£¼ì‹œ': [37.4224, 127.2554],
        'ê²½ë¶ í¬í•­ì‹œ': [36.0223, 129.3459],
        'ê²½ê¸° ê¹€í¬ì‹œ': [37.6161, 126.7066],
        'ê²½ë¶ ì•ˆë™ì‹œ': [36.5661, 128.7395],
        'ê²½ê¸° ì•ˆì‚°ì‹œ': [37.3201, 126.8302],
        'ê²½ê¸° êµ¬ë¦¬ì‹œ': [37.5980, 127.1257],
        'ê²½ê¸° ê´‘ëª…ì‹œ': [37.4765, 126.8666],
        'ëŒ€ì „ ì„œêµ¬': [36.3484, 127.3844],
        'ê²½ê¸° ë¶€ì²œì‹œ': [37.5047, 126.7669],
        'ì¶©ë‚¨ ì•„ì‚°ì‹œ': [36.7982, 127.0271],
        'ì¸ì²œ ë¶€í‰êµ¬': [37.4877, 126.7055],
        'ëŒ€êµ¬ ë‚¨êµ¬': [35.8256, 128.6030],
        'ì„œìš¸ ë…¸ì›êµ¬': [37.6548, 127.0771],
        'ë¶€ì‚°': [35.1796, 129.0757],
        'ê²½ê¸° í•˜ë‚¨ì‹œ': [37.5281, 127.2112]
    }

    # ë§‰ëŒ€ ê·¸ë˜í”„ ì´ë¯¸ì§€ ìƒì„± í•¨ìˆ˜
    def create_bar_chart_image(job_count_for_location):
        """ì§ì¢…ë³„ ê³µê³  ìˆ˜ë¥¼ ë‚˜íƒ€ë‚´ëŠ” ë§‰ëŒ€ ê·¸ë˜í”„ë¥¼ ìƒì„±í•˜ê³  base64 ì´ë¯¸ì§€ë¡œ ë³€í™˜"""
        job_count_for_location = job_count_for_location.sort_values('ê³µê³  ìˆ˜', ascending=False)

        # ê·¸ë˜í”„ ì„¤ì •
        fig, ax = plt.subplots(figsize=(8, 5))

        # ì§ì¢… ë° ê³µê³  ìˆ˜
        job_categories = job_count_for_location['ì§ì¢…']
        job_counts = job_count_for_location['ê³µê³  ìˆ˜']

        # ì§ì¢…ë³„ ìƒ‰ìƒ ì„¤ì •
        colors = [st.session_state.color_scheme.get(job, "#000000") for job in job_categories]

        ax.bar(job_categories, job_counts, color=colors)
        ax.set_xlabel('ì§ì¢…')
        ax.set_ylabel('ê³µê³  ìˆ˜')
        ax.set_title('ì§ì¢…ë³„ ê³µê³  ìˆ˜')
        plt.xticks(rotation=45)

        # ì´ë¯¸ì§€ ë³€í™˜
        img_stream = io.BytesIO()
        plt.savefig(img_stream, format='png', bbox_inches="tight")
        img_stream.seek(0)
        plt.close(fig)

        # base64 ë³€í™˜
        img_b64 = base64.b64encode(img_stream.getvalue()).decode()
        img_tag = f'<img src="data:image/png;base64,{img_b64}" width="600" height="400"/>'
        
        return img_tag


    # ì§ì¢… ì„ íƒ (checkbox ë²„íŠ¼)
    selected_jobs = []
    selected_jobs = [job for job in st.session_state.color_scheme.keys() if st.checkbox(job, key=job)]

    # ì§ì¢… ì„ íƒì— ë§ëŠ” ì§€ì—­ë³„ ê³µê³  ìˆ˜ ê³„ì‚°
    job_count_filtered = job_count[job_count['ì§ì¢…'].isin(selected_jobs)]

    # 'ê³µê³  ìˆ˜'ë¥¼ intë¡œ ë³€í™˜
    job_count_filtered['ê³µê³  ìˆ˜'] = job_count_filtered['ê³µê³  ìˆ˜'].astype(int)

    # ì§ì¢…ì´ ì„ íƒë˜ì§€ ì•Šì•˜ìœ¼ë©´, ì§€ë„ì™€ ìˆœìœ„ë¥¼ í‘œì‹œí•˜ì§€ ì•Šë„ë¡ ì²˜ë¦¬
    # ì„ íƒëœ ì§ì¢…ì´ ìˆì„ ê²½ìš° ì§€ë„ í‘œì‹œ
    if selected_jobs:
        # ì„¸ì…˜ ìƒíƒœì— ì§€ë„ ì €ì¥í•˜ì—¬ ì´ˆê¸°í™” ë°©ì§€
        if 'map_object' not in st.session_state:
            st.session_state.map_object = folium.Map(location=[36.5, 128], zoom_start=7)

        m = st.session_state.map_object  # ê¸°ì¡´ ì§€ë„ ê°ì²´ ê°€ì ¸ì˜¤ê¸°
        marker_cluster = MarkerCluster().add_to(m)  # ë§ˆì»¤ í´ëŸ¬ìŠ¤í„° ì¶”ê°€

        job_count_filtered = job_count[job_count['ì§ì¢…'].isin(selected_jobs)]

        for location_name in total_job_count['ì§€ì—­']:
            total_jobs_for_location = total_job_count[total_job_count['ì§€ì—­'] == location_name]['ì´ ê³µê³  ìˆ˜'].values[0]
            job_count_for_location = job_count_filtered[job_count_filtered['ì§€ì—­'] == location_name]

            if not job_count_for_location.empty and location_name in location_coords:
                coordinates = location_coords[location_name]

                # ê·¸ë˜í”„ ìƒì„±
                img_tag = create_bar_chart_image(job_count_for_location)

                for job_category in selected_jobs:
                    job_data = job_count_for_location[job_count_for_location['ì§ì¢…'] == job_category]
                    if not job_data.empty:
                        job_count_value = job_data['ê³µê³  ìˆ˜'].values[0]
                        marker_size = max(5, min(np.log1p(job_count_value) * 15, 200))

                        # ìƒ‰ìƒ ì ìš©
                        color = st.session_state.color_scheme.get(job_category, "#000000")

                        folium.CircleMarker(
                            location=coordinates,
                            radius=marker_size,
                            color=color,
                            fill=True,
                            fill_color=color,
                            fill_opacity=0.4,
                            popup=folium.Popup(
                                f"""
                                <strong>{location_name}</strong><br>
                                {job_category} ê³µê³  ìˆ˜: {job_count_value}<br>
                                ì´ ê³µê³  ìˆ˜: {total_jobs_for_location}<br>
                                {img_tag}  <!-- ê·¸ë˜í”„ í¬í•¨ -->
                                """,
                                max_width=800
                            )
                        ).add_to(marker_cluster)


        # ì„ íƒí•œ ì§ì¢…ì´ ìˆì„ ê²½ìš°ì—ë§Œ ì‹¤í–‰
        if selected_jobs:
            job_count_by_location = job_count_filtered.groupby(['ì§€ì—­', 'ì§ì¢…'])['ê³µê³  ìˆ˜'].sum().reset_index()
            job_count_by_location = job_count_by_location.sort_values('ê³µê³  ìˆ˜', ascending=False)

            col1, col2 = st.columns([2, 1])  # ì²« ë²ˆì§¸ ì—´(ì§€ë„) / ë‘ ë²ˆì§¸ ì—´(ìˆœìœ„)

            with col1:
                st.session_state.map_object = m  # ë³€ê²½ëœ ì§€ë„ ì €ì¥

                folium_static(m, width=1000, height=700)

            with col2:
                st.header("ğŸ“Œ ì§ì¢…ë³„ ê³µê³ ê°€ ë§ì€ ì§€ì—­ ìˆœìœ„")

                top5_overall = job_count_by_location.groupby("ì§€ì—­")["ê³µê³  ìˆ˜"].sum().reset_index()
                top5_overall = top5_overall.sort_values("ê³µê³  ìˆ˜", ascending=False).head(5)
                st.subheader("ğŸ”¹ ì „ì²´ ì§ì¢… ê¸°ì¤€ Top 5 ì§€ì—­")
                st.dataframe(top5_overall[['ì§€ì—­', 'ê³µê³  ìˆ˜']], use_container_width=True)

    else:
        st.markdown("""
        <div style="background-color: #f4f4f9; padding: 20px; border-radius: 10px; text-align: center;">
            <h2 style="color: #e76f51;">ì§ì¢…ì„ ì„ íƒí•˜ì„¸ìš”</h2>
            <p style="color: #2a9d8f;">ì›í•˜ëŠ” ì§ì¢…ì„ ì„ íƒí•˜ì—¬ ê³µê³ ë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.</p>
        </div>
        """, unsafe_allow_html=True)

with tab4:
    st.markdown("<div class='title'>Job market RAG Chatbot</div>", unsafe_allow_html=True)
    st.markdown("<div class='subtitle'>êµ¬ì§ì— ëŒ€í•œ ëª¨ë“  ê¶ê¸ˆì¦ì„ ì—¬ê¸°ì—!</div>", unsafe_allow_html=True)

    # Initialize or retrieve chat history from session state.
    if "chat_history" not in st.session_state:
        st.session_state.chat_history = []  # List of tuples: (user message, bot response)

    # Display existing chat history.
    chat_container = st.container()
    if st.session_state.chat_history:
        for user_msg, bot_msg in st.session_state.chat_history:
            chat_container.markdown(f"**User:** {user_msg}")
            chat_container.markdown(f"**Bot:** {bot_msg}")

    # User input for the new message.
    user_input = st.text_input("Your message:", key="user_input")

    if st.button("Send"):
        if user_input.strip() != "":
            # Append the user message with an empty bot response (to be updated)
            st.session_state.chat_history.append((user_input, ""))
            # Create a placeholder for streaming the bot's answer.
            response_placeholder = st.empty()
            full_response = ""
            # Use previous chat history (excluding the last incomplete one) as context.
            chat_history_context = st.session_state.chat_history[:-1]
            # Stream the response.
            for partial_response in chat_function(user_input, chat_history_context):
                full_response = partial_response
                response_placeholder.markdown(full_response)
                time.sleep(0.05)  # small sleep to simulate streaming
            # Update the chat history with the final answer.
            st.session_state.chat_history[-1] = (user_input, full_response)
            # The updated session state will refresh the chat display on the next interaction.

    # Button to clear the chat history.
    if st.button("Clear Chat History"):
        st.session_state.chat_history = []

# íšŒìƒ‰ ì„  ì¶”ê°€
st.markdown('<div class="divider"></div>', unsafe_allow_html=True)

logo_image = image_to_base64(logo_image_path)
st.markdown(f"""
        <div class="logo">
            <br><br><center><img src="data:image/png;base64,{logo_image}" width='500'>
        </div>
""", unsafe_allow_html=True)